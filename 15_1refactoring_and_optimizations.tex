\subsection{Refactoring and Optimizations} \label{ssec:refactoring_and_optimizations} % \subsubsection{Code Clean-up} \label{sssec:cleanup}
Before any large change or algorithm implementation is considered on the software, it was decided to do a so-called ``code-cleanup''.
This was considered necessary mainly because of two reasons:

First, the current implementation had a low readability, presenting various issues like uneven indentation style, non-compliance with the Java code conventions~\cite{sun1997java}, inconsistent and arbitrary variable and method names, among many others.
This can be seen in the link to the original repository provided at Section \ref{add:code_and_reproducibility}.

The second reason is the large presence of many unintentional, unmanaged architectural technical debt (technical debts and their classification are explained briefly in Appendix \ref{add:technical_debt}).
% While most technical debts are invisible without a detailed analysis, the symptoms for many of them can be clear to most experienced programmers.
Many instances of these debts were found in the DC code, in the form of repeated portions of code, a general lack of error checking and reporting and a general lack of comments in difficult-to-understand sections of code, among others.

Due to both these reasons and simply to improve the author's familiarity with the code, the previously mentioned clean-up was done.
The measures implemented in this process are the following:

    \begin{itemize}
        \item \textbf{Addition of comments}: A comprehensive list of the segments of code with a non-intuitive purpose was written.
        A small research was then performed for each point in the list, looking into the math, physics or general algorithms from which it could be derived.
        When this was found, a comment was written either providing a small explanation or referring to the name of the formula or algorithm used.
        When this research was unfruitful, the original author of the code was contacted so that she could provide enough information about the code segment so as to write this explanatory comment (Contact information is given in Appendix \ref{add:code_and_reproducibility}).
    
        Apart from the general comments, a complete JavaDoc documentation was added to the most important classes and methods in the DC code, with sparse documentation added also to hard-to-understand classes or methods in less critical classes.
    
        \item \textbf{Indentation Consistency}: Considering that the indentation style at the DC software was very inconsistent, this was fixed to improve readability.
        Now, the ``ideal length'' of indentations and the use of tab characters or space characters for it has been a long-running debate between programmers, so instead of finding the ``best option'' for it, the current standard used in most of the CLAS12 codebase was implemented, which simply is four space characters per indent.
    
        \item \textbf{Line Length Fixes}: While the code doesn't follow a rigorous standard, a line length of $100$ characters can be seen somewhat consistently thorough the CLAS12 codebase, sticking to the java conventions~\cite{sun1997java}.
        This line length is not strictly applied to the DC code, but instead some extremely long ($>300$ characters) segments of code are separated into various lines to aid readability.
    
        \item \textbf{Class, Method and Variables Names}: The standard Java conventions stipulate a consistent camel case naming standard, and while most of the code follows this style, the DC code tends to stray away from it in many ways.
        These include variables in lower case with or without underscores, variables and methods starting with an underscore, methods starting with uppercase, etc.
        The standard naming convention is applied to all of these instances.
    \end{itemize}

\subsubsection{Refactoring}\label{sssec:refactoring}
By definition, refactoring is the art of safely improving the design of existing code without changing its behaviour.
Changes done to the code through refactoring do not add new functionalities or represent design improvements, but only work to eliminate or reduce \textbf{code \textit{smells}}. % Note: I feel like refactoring does add design improvements but the usual java documentation on this says that by definition they don't so idk.
Code \textit{smells} are warning signs about potential problems in the code, meaning points that are worthy of a revision~\cite{wake2004refactoring}.

A small list of some the code \textit{smells} found in the DC code together with examples and the treatment done follows.
It is worth noting that this list is far from comprehensive, and just lists the \textit{smells} relevant to the discussion:
    \begin{itemize}
        \item \textbf{Long Methods}: Many methods with a very large amount of lines can be found thorough the code.
        In a normal situation this wouldn't be considered to be a big issue, but in the case of DC, many of these large methods contain repeated code or very similar segments, which in itself is considered a problem since it breeds inconsistencies and longer implementation times to any change done to the code.
        
        An example of this is the method \texttt{RK4transport} from the class \texttt{RungeKutta}, from the package \texttt{org.jlab.rec.dc.track.fit}, which is $269$ lines long.
        It's worth mentioning that the algorithm implemented in this method is \textbf{Runge Kutta 4}, and is described in Section \ref{ssec:framework_rk4}.

        The treatment for this problem is easy to implement, and involves simply splitting the method.
        What is done to do this is to extract the repeating segments into their own private methods, allowing then the original method to call these new methods.
        The benefit of this change is the elimination of duplicated code and a large performance improvement due to the elimination of unnecessary loops, which is explained further in Section \ref{sssec:optimizations}.
    
        In the mentioned example, the method can be split into various methods: First, the computation of $k_1$, $k_2$, $k_3$ and $k_4$ can all be done in the same method, reducing $172$ lines of code into $4$ method calls, with the new method being only $45$ lines long.
        After this, the final $RK4$ computation can be left as is, and some extra steps done to compute the covariance matrix can all be split into their own methods, easing the future debugging of the method and allowing each computation to be changed or optimized separately.
        The final \texttt{RK4transport} method is left with a total of $33$ lines of code with $7$ method calls.
        It's worth noting that this number can be further reduced to $20$ lines by packing intermediary variables into arrays, but to avoid the danger of reducing code readability it was considered a good idea to avoid this option.

        \item \textbf{Long Parameter Lists}: Similar to the last \textit{smell}, long parameter lists can be found thorough the DC code.
        In most cases specific to the software in study, these lists are expressed in the form of a long list of inputs for methods.
        An example for this is the \texttt{getTrackInitFit} method in the class \texttt{TrackCandListFinder} contained in the \texttt{org.jlab.rec.dc.track} package, where $20$ parameters are given to the method.
        These parameters are the integer \texttt{sector}, a long list of doubles: \texttt{x1}, \texttt{y1}, \texttt{z1}, \texttt{x2}, \texttt{y2}, \texttt{z2}, \texttt{x3}, \texttt{y3}, \texttt{z3}, \texttt{ux}, \texttt{uy}, \texttt{uz}, \texttt{thX}, \texttt{thY}, \texttt{theta1}, \texttt{theta3}, \texttt{iBdl}, \texttt{TORSCALE}, and an instance of the \texttt{Swim} class.
    
        Fixing such issues is usually easy, just requiring some degree of packaging for the parameters.
        For the example given, the previosly mentioned method is called by \texttt{GetTrackCands}, another method from the same class.
        In this method, three \textbf{cross} objects are unpacked to obtain the first $14$ doubles from the mentioned list, with two more doubles coming from clusters contained in the crosses and finally \texttt{iBdl} coming from the trajectory formed by the crosses.
        These \textbf{cross} objects are sets of two clusters from adjacent superlayers, while the \texttt{iBdl} variables denotes the integral of the magnetic field. % Note: I don't know exactly what iBdl is but no sources I found say more than "Integral of the magnetic field" so at least apparently physicists get it.
        The \texttt{sector} integer mentioned can also be obtained from the first cross.
        As can be seen, the $20$ input parameters given to the method can be replaced with three \texttt{cross} objects, the \texttt{TORSCALE} value and the instance of the \texttt{Swim} class previously mentioned, reducing the parameter list to four objects and only one parameter. % Note: Maybe an UML diagram or something like it might be useful here.
    
        \item \textbf{Commented and Dead Code}: This \textit{smell} consists in the presence of commented code, and is usually caused by either old code that the programmer decided to leave commented instead of deleting in case that it becomes useful in the future.
        Dead code is the phenomena that occurs when new methods are written and old and unused methods are never deleted.
        Both commented and dead code segments are present in large quantities in the DC software, and after a meeting between the author and the programmer it was decided to simply remove all this code since analyzing which segments would be useful or not would probably be too large a task for the minimal benefit provided by doing it.

        \item \textbf{Duplicated Code}: This \textit{smell} is characterized by two or more code fragments that look almost or completely identical.
        Duplication usually occurs when multiple programmers are working on different parts of the same program at the same time, but in the case of the DC software this can be attributed to accidents. % Note: More elaboration here might be useful.
        The solution to this problem is fairly simple: extract the duplicated code, create a new method to run this code and have both instances call this new method.
    
        In the case of the DC software, there is one instance where code duplication is very easily spotted; both the \texttt{RoadFinder} class from the \texttt{org.jlab.rec.dc.trajectory} package and the \texttt{CrossListFinder.TrajectoryParametriz} class from the \texttt{org.jlab.rec.dc.cross} package contain the exact same method, even using the same name, \texttt{evaluate}, and the code in this method does the same: fit a set of points into a line and return the parameters of the fit along with the $\chi^2$ probability and the number of degrees of freedom. % Note: Maybe this paragraph is too angry.
    
        \item \textbf{Data Class}: The final \textit{smell} that will be discussed in this work is the so-called ``data class'' \textit{smell}, which refers to a class that contains only fields and setters and getters to access them.
        In the case of the DC codebase, an example of this would be both the \texttt{StateVec} and the \texttt{CovMat} classes from the \texttt{org.jlab.rec.dc.track.fit} package.
        Both classes just define a state vector (described in Section \ref{ssec:framework_tf}) and a covariance matrix (described in Appendix \ref{add:covariance_matrix}), without providing any methods apart from the basic definition of the concepts.
    
        The treatment for this problem is through the encapsulation of the data class inside another class, ideally one that uses it.
        In the example, both these classes were encapsulated in another class named \texttt{StateVecs} from the same package.
    \end{itemize}

\subsubsection{Optimizations}\label{sssec:optimizations}
While cleaning up and refactoring the code, many optimizations were applied to the critical areas described in Section \ref{ssec:prof_results} so as to accelerate the bottlenecks and speed up the whole CLAS12 software.
These optimizations involve the addition of variables to precompute results instead of calculating them several times, the reduction of complexity orders by removing unnecessary loops, and the improvements brought by simply restructuring the code as described in the last Section.

% Note: Here I could talk about how the precomputation of results helped (and they helped a ton), and how to do the reduction of complexity with examples, especially considering the massive changes in performance this step brought to the code. I'd need some references for this, but I'm afraid I can't find much on that.